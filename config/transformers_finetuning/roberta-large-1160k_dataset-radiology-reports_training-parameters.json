{
"ddp_find_unused_parameters": false,
"eval_steps": 10000,
"evaluation_strategy": "steps",
"learning_rate": 5e-5,
"logging_steps": 10,
"logging_strategy": "steps",
"num_train_epochs": 10,
"output_dir": "/nlp/models/transformers_finetuning/roberta-large-1160k_dataset-radiology-reports_n-epochs-10",
"per_device_train_batch_size": 16,
"per_device_eval_batch_size": 16,
"report_to": "tensorboard",
"save_strategy": "steps",
"save_steps": 1000,
"save_total_limit": 5,
"weight_decay": 0.01
}